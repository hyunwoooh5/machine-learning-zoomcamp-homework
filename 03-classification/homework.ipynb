{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcad0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37368c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-17 03:10:31--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2025-09-17 03:10:31 (21.5 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a811956",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For caterogiral features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9cdfb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"course_lead_scoring.csv\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb1a155b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d939a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5fffa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "numerical_columns = list(df.dtypes[(df.dtypes != 'object') & (df.columns != 'converted')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fde0080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['lead_source', 'industry', 'employment_status', 'location'],\n",
       " ['number_of_courses_viewed',\n",
       "  'annual_income',\n",
       "  'interaction_count',\n",
       "  'lead_score'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns, numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c53b729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd165f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical_columns:\n",
    "    df.loc[:,c] = df[c].fillna('NA')\n",
    "\n",
    "for c in numerical_columns:\n",
    "    df.loc[:,c] = df[c].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db33f89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9970fe",
   "metadata": {},
   "source": [
    "# Q1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `industry`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4595f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297f3a8",
   "metadata": {},
   "source": [
    "# Q2\n",
    "\n",
    "Create the for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae580311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.023565</td>\n",
       "      <td>-0.004879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.015610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.023565</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                  1.000000       0.009770   \n",
       "annual_income                             0.009770       1.000000   \n",
       "interaction_count                        -0.023565       0.027036   \n",
       "lead_score                               -0.004879       0.015610   \n",
       "\n",
       "                          interaction_count  lead_score  \n",
       "number_of_courses_viewed          -0.023565   -0.004879  \n",
       "annual_income                      0.027036    0.015610  \n",
       "interaction_count                  1.000000    0.009888  \n",
       "lead_score                         0.009888    1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical_columns].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f9b93",
   "metadata": {},
   "source": [
    "# Split data\n",
    "\n",
    "* Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "* Make sure that the target value `y` is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3700df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f5bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7266d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 9), (293, 9), (293, 9))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97ad918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "y_test = df_test['converted'].values\n",
    "\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a72d68",
   "metadata": {},
   "source": [
    "# Q3\n",
    "\n",
    "* Calculate the mutual information score between `y` and other categorical variables in the dataset. Use the training set only.\n",
    "* Round the scores to 2 decimals using `round(score, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb7bb568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source: 0.04\n",
      "industry: 0.01\n",
      "employment_status: 0.01\n",
      "location: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "for c in categorical_columns:\n",
    "    print(f'{c}: {round(mutual_info_score(y_train, df_train[c]),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc429d6",
   "metadata": {},
   "source": [
    "# Q4\n",
    "\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a7f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58df01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[categorical_columns + numerical_columns].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical_columns + numerical_columns].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84d977f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6996587030716723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1e0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "y_pred_decision = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "accuracy = (y_pred_decision == y_val).mean()\n",
    "\n",
    "print(f\"accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dee04b",
   "metadata": {},
   "source": [
    "# Q5\n",
    "\n",
    "* Let's find the least useful feature using the *feature elimination* technique.\n",
    "* Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3360f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source is removed. Difference is 0.13993174061433444\n",
      "industry is removed. Difference is 0.14675767918088733\n",
      "employment_status is removed. Difference is 0.15017064846416384\n",
      "location is removed. Difference is 0.15017064846416384\n",
      "number_of_courses_viewed is removed. Difference is 0.13993174061433444\n",
      "annual_income is removed. Difference is 0.13310580204778155\n",
      "interaction_count is removed. Difference is 0.14334470989761094\n",
      "lead_score is removed. Difference is 0.15017064846416384\n"
     ]
    }
   ],
   "source": [
    "features = categorical_columns + numerical_columns\n",
    "\n",
    "for f in features:\n",
    "    features_removed = [i for i in features if i != f]\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "\n",
    "    train_dict = df_train[features_removed].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "    val_dict = df_test[features_removed].to_dict(orient='records')\n",
    "    X_val = dv.fit_transform(val_dict)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    y_pred_decision = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "    print(f\"{f} is removed. Difference is {accuracy - (y_pred_decision == y_val).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4b81e",
   "metadata": {},
   "source": [
    "# Q6\n",
    "\n",
    "* Now let's train a regularized logistic regression.\n",
    "* Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "* Train models using all the features as in Q4.\n",
    "* Calculate the accuracy on the validation dataset and round it to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "237cf4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01: 0.6996587031\n",
      "0.1: 0.6996587031\n",
      "1: 0.6996587031\n",
      "10: 0.6996587031\n",
      "100: 0.6996587031\n"
     ]
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[categorical_columns + numerical_columns].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical_columns + numerical_columns].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "for c in 0.01, 0.1, 1, 10, 100:\n",
    "    model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    y_pred_decision = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "    accuracy = (y_pred_decision == y_val).mean()\n",
    "\n",
    "    print(f\"{c}: {accuracy:0.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
